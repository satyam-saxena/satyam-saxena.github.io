---
layout: post
title:  "Sample efficient Reinforcement Learning with Human Feedback"
date:   2024-01-07 11:41:51 +0000
categories: rlhf
---

Core Problem

- Preference based Feedback has become an important part of many applications in reinforcement learning where access to the direct reward function is not feasible.
- The core issue with utilising RLHF for real world problems is the acquisition cost of collecting preference dataset
- Alignment of Large language models with human preferences is a core problem. In the current pipeline, the pre-trained LLM goes into the Supervised fine tuning step
- In the subsequent step, the LLMs undergoes RLHF training process using the preference data over multiple completions generated by the system. This works by first creating a reward model, which then fine-tunes the LLMs by assigning scores to its completions.
- As the number of variations required for these LLMs increase data annotations cost will become the biggest bottleneck for training these models.

Propopal

- In this paper, author proposed a technique which can be used to find contexts where there’s the largest uncertainty in order to identify good policy
- They have framed the problem as an active contextual dueling bandit problem.
- The core proposal of this paper is the Contextual Borda function for active exploration in reinforcement learning.
- This allows the system to generate a sampling and policy selection rule which allows us to output a policy with provably low sub-optimality.
- Essentially, the sampling rule selects contexts at which there is maximum uncertainty over the “Borda value function”

Impact

- Able to show similar performance with fewer input samples









You’ll find this post in your `_posts` directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run `jekyll serve`, which launches a web server and auto-regenerates your site when a file is updated.

Jekyll requires blog post files to be named according to the following format:

`YEAR-MONTH-DAY-title.MARKUP`

Where `YEAR` is a four-digit number, `MONTH` and `DAY` are both two-digit numbers, and `MARKUP` is the file extension representing the format used in the file. After that, include the necessary front matter. Take a look at the source for this post to get an idea about how it works.

Jekyll also offers powerful support for code snippets:

{% highlight ruby %}
def print_hi(name)
  puts "Hi, #{name}"
end
print_hi('Tom')
#=> prints 'Hi, Tom' to STDOUT.
{% endhighlight %}

Check out the [Jekyll docs][jekyll-docs] for more info on how to get the most out of Jekyll. File all bugs/feature requests at [Jekyll’s GitHub repo][jekyll-gh]. If you have questions, you can ask them on [Jekyll Talk][jekyll-talk].

[jekyll-docs]: https://jekyllrb.com/docs/home
[jekyll-gh]:   https://github.com/jekyll/jekyll
[jekyll-talk]: https://talk.jekyllrb.com/
